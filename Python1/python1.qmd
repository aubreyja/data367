---
title: "Python 1: Baseball Data Analysis with Pandas, pybaseball, and Quarto"
subtitle: "DATA 367 — Intro Sports Analytics Workflow"
author: "YOUR NAME"
date: "Due: {{DUE DATE}}"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: false
    code-fold: false
execute:
  echo: true
  warning: true
  message: true
  error: true
---

## Overview

In this assignment you will:

-   set up a basic **sports analytics** workflow in **Python** using **pandas** and **numpy**,
-   access a real baseball dataset using the **pybaseball** library,
-   answer a clearly stated baseball question using **correlation** and a simple **regression**,
-   write up your analysis in **Quarto** (`.qmd`),
-   and use **Git + GitHub Classroom** to **clone**, **commit**, and **push** your work.

This assignment is designed to introduce you of (or remind you of) the pieces of a typical data analysis pipeline (load → clean → explore → model → communicate), and to get you comfortable using a sports data library and the GitHub Classroom workflow.

------------------------------------------------------------------------

## Academic integrity and collaboration

You may discuss *ideas* and *debugging strategies* with classmates, but your code, figures, and written analysis must be your own work unless your instructor explicitly authorizes collaboration. If you use an external source (AI, documentation, blog post, etc.), cite it in a short note.

## Use of Generative AI

Generative AI tools are increasingly used in contemporary professional data-science practice, and their thoughtful use is permitted for this assignment. However, you are a student developing professional skills, not yet a practicing professional. You are therefore fully responsible for the correctness, clarity, and quality of all work you submit, including verifying any AI-generated suggestions and making independent decisions about methods, code, and interpretation.

AI tools may assist with brainstorming, explanation, or coding support, but you should consider whether your use of AI is helping you build the skills required of a successful data-science professional, or merely reproducing output you do not fully understand.

Any use of generative AI must be explicitly acknowledged. Failure to disclose AI use may be considered a violation of the Code of Academic Integrity. If you are unsure whether a particular use of AI is appropriate for this assignment, please ask before submitting.

## AI Acknowledgment Statement

I acknowledge the use of \[AI system name(s)\] to \[describe how the tool was used\]. Prompts used included \[link or pasted prompt(s)\].

------------------------------------------------------------------------

## GitHub Classroom workflow

### Accept the assignment and clone your repository

1.  **Accept the assignment** using the GitHub Classroom link provided on the course site.
2.  After acceptance, you will have your own private repository on GitHub.

Now clone it to your computer.

#### Option A: Command line (recommended)

Open a terminal and run:

``` bash
# 1) Choose a folder where you keep course work
cd ~/Documents   # change as needed

# 2) Clone your GitHub Classroom repo (replace URL with YOUR repo)
git clone https://github.com/<ORG>/<REPO>.git

# 3) Enter the repo
cd <REPO>

# 4) Confirm you are on the main branch (or whatever your repo uses)
git status
```

#### Option B: Positron

-   In Positron: **File → New Project** (or **Open Folder**)
-   Choose: **Clone Git Repository**
-   Paste your GitHub Classroom repository URL
-   Choose a local folder and click **Clone**
-   Open the `.qmd` file in the editor

------------------------------------------------------------------------

## Environment and packages

### Required packages

We will use:

-   `pandas` and `numpy` (core data analysis)
-   `matplotlib` (plots)
-   `pybaseball` (baseball data access)
-   `statsmodels` (simple regression and statistical summaries)

If you do not have them installed, using one of the following commands may do it:

#### Option A: `pip`

``` bash
pip3 install pandas numpy matplotlib pybaseball statsmodels
```

#### Option B: `conda` / `mamba`

``` bash
conda install pandas numpy matplotlib statsmodels
pip3 install pybaseball
```

### Import packages

Python’s standard library is intentionally small. Most data analysis work relies on **external packages** (also called *modules* or *libraries*) that extend Python with tools for data handling, visualization, and statistical modeling. Before you can use a package, you must **import** it.

In the code block below, we import the packages needed for this analysis.

```{python}
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Baseball data library
from pybaseball import batting_stats

# Basic regression
import statsmodels.api as sm
```

In Python, we use the import statement to bring in tools from external libraries. However, how we write that statement changes how we access those tools in our code.

Here is a breakdown of the common patterns you will see in this assignment and throughout the industry:

1.  Importing with Aliases (as): Most major data science libraries have "standard" aliases. While you could technically name them anything, using these conventions makes your code readable to other analysts.

    `import pandas as pd`: Instead of typing `pandas.DataFrame()`, you just type `pd.DataFrame()`.\
    \
    `import numpy as np`: Shortens the frequent calls to math functions.

2.  The f`rom ... import ...` style: This is used when you only need a specific "tool" (a function or class) from a large library, rather than the whole thing.\
    When to use it: Use this for specific tasks, like from `pybaseball import batting_stats`. This allows you to call `batting_stats()` directly without typing `pybaseball.batting_stats()`.

    Why use it: It keeps your code "cleaner" and can slightly improve performance by not loading unnecessary parts of a large package into your local namespace.

3.  Namespace Safety: The main reason we use pd. or np. prefixes (the "namespace") is to avoid naming collisions. If you imported everything directly and two different libraries both had a function named mean(), Python wouldn't know which one you intended to use. Prefixes act like "last names" for functions to keep them distinct.

### Sanity check

A **sanity check** is a quick, low-stakes test to ensure your environment is behaving as expected before you start your analysis.

```{python}
print("numpy:", np.__version__)
print("pandas:", pd.__version__)
```

When we print `__version__`, we are verifying:

-   **Installation:** That the library is actually installed and accessible.

-   **Pathing:** That Quarto is using the correct Python environment.

-   **Compatibility:** That we are using a version of the library that supports the features we plan to use.

We also run a quick `batting_stats` call for a single year to ensure your computer can successfully connect to the Baseball-Reference/FanGraphs servers.

```{python}
# Test pybaseball connection with a small data pull
try:
    test_data = batting_stats(2023).head(3)
    print("pybaseball connection: SUCCESS")
except Exception as e:
    print("pybaseball connection: FAILED")
    print(e)
```

------------------------------------------------------------------------

## A baseball dataset: MLB team batting stats

We will use `pybaseball.batting_stats(year)` which returns season-level **team batting** stats for MLB.

-   Each row is a team-season (one team in one year).
-   Columns include common batting measures like **OBP** (on-base percentage), **SLG** (slugging), **BB%** (walk rate), **K%** (strikeout rate), and **R** (runs scored).

### Load the data

Pick a year. Use a recent season so it feels current (but any year supported by the library is fine).

```{python}
YEAR = 2024  # you may change this

df = batting_stats(YEAR)
```

### Inspect the columns and missingness

In data analysis, we never assume the data is "clean" just because it loaded. We use exploratory functions to orient ourselves. Here is a breakdown of the inspection steps we use in the assignment and why they are essential.

`df.head()`

**What it does**: Returns the first 5 rows of the DataFrame.

**Why do it**: This is your first "look" at the data. It confirms that the columns aligned correctly and gives you a sense of the data types (e.g., are the team names strings? are the stats decimals?).

```{python}
df.head()
```

`df.shape` 

**What it does**: Returns a tuple representing the dimensionality: (rows, columns). (Note: This is an attribute, not a function, so it doesn't use parentheses).

**Why do it**: It tells you the scale of your dataset. If you expected 30 teams but see 600 rows, you know you’ve likely pulled multi-year data or individual player stats instead of team stats.

```{python}
df.shape
```

`df.columns` 

**What it does**: Lists the names of every column in the dataset.

**Why do it**: `pybaseball` datasets often have over 300 columns. You need the exact spelling and capitalization of column names (e.g., is it R or runs?) to select them later without causing KeyErrors.

```{python}
df.columns
```

`df.isna().sum().sort_values(ascending=False).head(15)` 

This is a "chained" command that performs several operations at once to check for missingness:

`.isna()`: Checks every cell to see if it is empty (NaN).

`.sum()`: Counts the number of True (missing) values for each column.

`.sort_values(ascending=False)`: Puts the columns with the most missing data at the top.

`.head(15)`: Limits the output to the top 15 "offenders."

**Why do it**: Missing data can break your math. If a column you plan to use as a predictor is 50% empty, your regression results will be misleading or your code will crash. This identifies those landmines early.

```{python}
df.isna().sum().sort_values(ascending=False).head(15)
```


## The Heart of the Analysis: Asking the Right Questions

Ok, this gets us some data ready to work with, but let's change directions a bit and take a braoder view.

In sports analytics, we aren't just "calculating numbers"; we are trying to solve puzzles. A typical front-office inquiry often starts with a simple, high-stakes question: **"What actually drives winning?"** or **"What metric best predicts our ability to score?"**

To be a good sports data scientist, you need to understand your sport, what data is available, and how to analyze it. Let's now talk a bit about data analysis. While modern "black-box" machine learning models are popular, they aren't always necessary. Often, a clean **correlation** or a **simple linear regression** provides the clarity needed to make a multi-million dollar decision.

### Our Example Question: OBP vs. SLG

For decades, the "Moneyball" revolution in baseball prioritized **On-Base Percentage (OBP)** over traditional stats like Batting Average. However, in the modern "Power and Precision" era, many teams prioritize **Slugging Percentage (SLG)** to maximize damage per hit.

We want to know: **In the current MLB landscape, which of these two "building blocks" of hitting is more strongly associated with a team’s ability to score runs?**

Let's see how we can start to answer this question with some elementary statistics.

---

### Correlation and Regression

We need to understand two fundamental tools:

#### 1. Pearson Correlation ()

For two numeric variables (X) and (Y), the **Pearson correlation** (r) measures linear association:

-   ($r \approx 1$): strong positive linear relationship
-   ($r \approx -1$): strong negative linear relationship
-   ($r \approx 0$): little to no linear relationship

Important caveats:

-   correlation does **not** imply causation,
-   correlation can be distorted by outliers,
-   correlation only measures **linear** association.

#### 2. Simple Linear Regression (OLS)

A simple regression models an outcome (Y) as:

$$Y = \beta\_0 + \beta\_1 X + \varepsilon.$$

Here: 

- $Y$ will be `R` (runs scored), 
- $X$ will be `OBP` or `SLG`.

Regression gives: 

- an estimated slope ($\hat{\beta}\_1$), 
- an ($R^2$) value (how much variance in $Y$ is explained by the model), 
- p-values and confidence intervals (useful, but interpret cautiously — this is observational data).

While correlation tells us *how strong* the link is, regression tells us the *rate of change*. It gives us a "best-fit" line.

## The Analysis

Let's use these tools to shed some light on the question above. To do this, we will first create a smaller analysis dataset to work with. 

### Why we create a focused analysis dataset

The raw data from `pybaseball` is incredibly comprehensive, often containing over 300 different statistical categories. While this is great for deep research, it can make simple analysis cumbersome. We create a smaller "analysis dataset" for several key reasons:

1. **Reducing Noise:** It is easier to focus on the relationship between Runs and OBP if you aren't scrolling past columns for "Inside-the-park HR" or "Catcher Interference." A focused subset creates a cleaner workspace.
2. **Memory and Speed:** While 30 MLB teams is a small amount of data, professional sports datasets often have millions of rows. Filtering for only the columns you need saves memory and keeps your code running fast.
3. **Preventing Errors:** We use the `.copy()` method to create a brand-new, independent object in memory. This avoids the common "SettingWithCopy" warning in pandas, ensuring that changes we make to our analysis data don't accidentally affect the original "master" dataset.
4. **Ensuring Data Integrity:** Statistical models like Linear Regression cannot handle missing values (`NaN`). By isolating our variables and running `.dropna()`, we ensure that every row in our final table is complete and ready for mathematical modeling.

```{python}
# 1. Define a list of strings containing the exact column names we want to keep.
# 'R' is our target variable (what we want to predict).
# 'OBP' and 'SLG' are our primary predictors.
# 'BB%' and 'K%' are additional variables for potential exploration.
cols = ["Team", "R", "OBP", "SLG", "BB%", "K%"]

# 2. Filter the original 'df' to keep only those columns.
# We use .copy() to create a new, independent object in memory.
# Without .copy(), 'data' would just be a "view" of 'df', 
# which can lead to a "SettingWithCopyWarning" when we try to clean or modify it.
data = df[cols].copy()

# 3. Display the first 5 rows of our new, smaller dataset to verify the filter worked.
data.head()

# 4. Handle missing data. 
# The .dropna() method removes any row that contains at least one missing value (NaN).
# In team-level season stats, missing data is rare, but this is a vital "safety" step.
data = data.dropna()

# 5. Check the final shape of our cleaned dataset.
# This confirms how many teams (rows) are left after dropping missing values.
data.shape
```


### Compute correlations

We begin by checking the correlation coefficient ($r$) for both metrics. This gives us a quick numerical "snapshot" of which variable shares a stronger linear link with run production.

```{python}
# Calculate Pearson correlation between Runs and our two main predictors
corr_obp = data["R"].corr(data["OBP"])
corr_slg = data["R"].corr(data["SLG"])

print(f"Correlation (Runs vs OBP): {corr_obp:.3f}")
print(f"Correlation (Runs vs SLG): {corr_slg:.3f}")
```

Write 2–4 sentences interpreting these values in context.

**Your interpretation (edit this):**

-   Correlation(R, OBP) = `{{YOUR VALUE}}`
-   Correlation(R, SLG) = `{{YOUR VALUE}}`

Interpretation: Write 2–4 sentences interpreting these values. Which one is higher? Does a high correlation here guarantee that one causes the other?

## Scatterplots with fitted regression lines

Before fitting any regression model, it is essential to **look at the data**. Summary statistics and correlation coefficients can be misleading (see *Anscombe’s Quartet*). Scatterplots allow us to check whether a relationship is genuinely linear, whether it is driven by a few extreme observations, and whether a linear model is even reasonable.

By overlaying a fitted regression line on the scatterplot, we can visually assess how well a single statistic explains run scoring across teams.

#### Runs vs OBP

```{python}
# --- Visualizing the Relationship: OBP vs Runs ---

# 1. Define our axes
# We assign our independent variable (Predictor) to x and dependent (Target) to y.
x = data["OBP"]
y = data["R"]

# 2. Create the figure object
plt.figure(figsize=(8, 5))

# 3. Create the Scatterplot
# 'alpha' makes the points slightly transparent, which helps if points overlap.
plt.scatter(x, y, alpha=0.7, label="Actual Teams")

# 4. Add Labels and Title
# Always label your axes! Use f-strings to keep the title dynamic to the YEAR.
plt.xlabel("On-Base Percentage (OBP)")
plt.ylabel("Runs Scored (R)")
plt.title(f"Correlation: Team OBP vs. Total Runs ({YEAR})")

# 5. Add a Best-Fit Line (Simple Linear Regression)
# np.polyfit calculates the slope (m) and intercept (b) for a 1st-degree polynomial (a line).
m, b = np.polyfit(x, y, 1)

# Create a sequence of 100 points from the min OBP to the max OBP to draw the line.
xline = np.linspace(x.min(), x.max(), 100)
yline = m * xline + b

# Plot the line on top of the scatterplot. 
plt.plot(xline, yline, color="red", linestyle="--", label="Regression Line")

# 6. Add a Legend and Grid
# A legend explains what the dots vs. the line represent.
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)

# 7. Display the final plot
plt.show()
```

#### Runs vs SLG

```{python}
# --- Visualizing the Relationship: SLG vs Runs ---

# 1. Define our axes
# We now switch our predictor to Slugging Percentage (SLG).
# The outcome (y) remains Runs Scored.
x_slg = data["SLG"]
y_runs = data["R"]

# 2. Create the figure object
# Using the same figsize ensures your report looks uniform.
plt.figure(figsize=(8, 5))

# 3. Create the Scatterplot
# We use a different color (green) to visually distinguish SLG from OBP.
plt.scatter(x_slg, y_runs, alpha=0.7, color="green", label="Actual Teams")

# 4. Add Labels and Title
plt.xlabel("Slugging Percentage (SLG)")
plt.ylabel("Runs Scored (R)")
plt.title(f"Correlation: Team SLG vs. Total Runs ({YEAR})")

# 5. Add a Best-Fit Line (Simple Linear Regression)
# We perform the same math: finding the slope (m) and intercept (b).
m_slg, b_slg = np.polyfit(x_slg, y_runs, 1)

# Generate 100 points for a smooth line from the minimum to maximum SLG value.
xline_slg = np.linspace(x_slg.min(), x_slg.max(), 100)
yline_slg = m_slg * xline_slg + b_slg

# Plot the regression line in red.
plt.plot(xline_slg, yline_slg, color="red", linestyle="--", label="Regression Line")

# 6. Add a Legend and Grid
plt.legend()
plt.grid(True, linestyle=':', alpha=0.6)

# 7. Display the final plot
plt.show()
```

## Linear Regression

In this section, we move from simple correlation to **Linear Regression**. While correlation tells us how *strongly* two variables are related, regression gives us the actual "formula" for that relationship.

### Why look at the "Fit" information?

When you run `model.summary()`, Python produces a dense table of statistical output. It can be overwhelming at first—it contains information about standard errors, t-statistics, and log-likelihood.

**Not all of this is important to us right now.** Professional analysts often ignore 80% of this table for an initial check. Right now, we are focusing on three specific indicators that tell us if our baseball theory actually holds water:

1. **The Sign and Size of the Slope (the `coef` of OBP or SLG):** This tells us the *direction* and *magnitude* of the relationship. Is the slope positive (more OBP = more Runs)? And how many *actual runs* do we gain for every point of OBP?
2. **The  (R-Squared):** This is your "Percentage of Story Explained" score. If the  is 0.80, it means 80% of the reason teams score different amounts of runs can be explained by their OBP alone.
3. **The Visual Fit:** We compare the numbers in these tables back to our plots. If the  is high, the dots on our scatterplot should be hugged very tightly to that red regression line.

### Executing the Regression Models

We use the `statsmodels` library (`sm`) because it provides the comprehensive summary tables required for professional statistical analysis.

#### Model A: Predicting Runs using OBP

```{python}
# 1. Add a 'constant' to our independent variable.
# By default, OLS models assume the line passes through (0,0). 
# Adding a constant allows for an 'intercept' (where the line hits the Y-axis).
X_obp = sm.add_constant(data["OBP"])

# 2. Fit the Ordinary Least Squares (OLS) model.
# We are modeling 'R' (target) based on 'X_obp' (predictor).
model_obp = sm.OLS(data["R"], X_obp).fit()

# 3. Print the full statistical summary.
model_obp.summary()

```

#### Model B: Predicting Runs using SLG

```{python}
# 1. Repeat the process for Slugging Percentage.
X_slg = sm.add_constant(data["SLG"])

# 2. Fit the model.
model_slg = sm.OLS(data["R"], X_slg).fit()

# 3. Print the summary.
model_slg.summary()

```

---

### How to read these results

When you look at the tables above, find these specific values:

* **R-squared:** Found in the top-right of the summary. Compare this value between Model A and Model B. The higher the number, the better that stat "explains" run scoring.
* **coef (Coefficient):** Found in the middle table.
  * The `const` coef is your **intercept**.
  * The `OBP` or `SLG` coef is your **slope**. This is the "rate of return" for that stat.

### More about $R^2$

In many sports analytics contexts, $R^2$ (pronounced "R-squared") is the most important number in your output because it directly measures the predictive power of a statistic. It is formally known as the Coefficient of Determination.Think of $R^2$ as a scale from 0 to 1 (or 0% to 100%) that answers the question: “How much of the 'Run Scoring Story' is actually explained by this specific stat?”

1. The "Story" of Variance

In any MLB season, teams score different amounts of runs. Some score 800, others score 600. This difference is called variance.If your model has an $R^2$ of 0.85, it means that 85% of the reason teams scored different amounts of runs can be explained by their OBP or SLG.The remaining 15% is "unexplained"—it’s the result of luck, base running, coaching, or other stats not in your model.

2. The Visual Connection

There is a direct link between the $R^2$ value and the plots you created earlier:

- High $R^2$: The data points are tightly packed around the red regression line. The line is a very "good fit" for the data.
- Low $R^2$: The data points are scattered widely. The line is just a "vague suggestion" of the trend.

3. Comparing OBP vs. SLG: 

This is the "smoking gun." If Model A (OBP) has an $R^2$ of .75 and Model B (SLG) has an $R^2$ of .82, the conclusion is clear: In that specific year, SLG was more reliable for predicting how many runs a team would score.





